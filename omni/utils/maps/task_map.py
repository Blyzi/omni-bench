from omni.utils.enums import Task, Benchmark


task_map: dict[Task, Benchmark] = {
    # LlmEvaluationHarness
    Task.HUMANEVAL: Benchmark.LLM_EVALUATION_HARNESS,
    Task.HUMANEVAL_PLUS: Benchmark.LLM_EVALUATION_HARNESS,
    Task.HUMANEVAL_INSTRUCT: Benchmark.LLM_EVALUATION_HARNESS,
    Task.MBPP: Benchmark.LLM_EVALUATION_HARNESS,
    Task.MBPP_PLUS: Benchmark.LLM_EVALUATION_HARNESS,
    Task.MMLU: Benchmark.LLM_EVALUATION_HARNESS,
    Task.ARC_EASY: Benchmark.LLM_EVALUATION_HARNESS,
    Task.ARC_EASY_CHAT: Benchmark.LLM_EVALUATION_HARNESS,
    Task.ARC_CHALLENGE: Benchmark.LLM_EVALUATION_HARNESS,
    Task.ARC_CHALLENGE_CHAT: Benchmark.LLM_EVALUATION_HARNESS,
    Task.HELLASWAG: Benchmark.LLM_EVALUATION_HARNESS,
    Task.IFEVAL: Benchmark.LLM_EVALUATION_HARNESS,
    Task.XNLI: Benchmark.LLM_EVALUATION_HARNESS,
    Task.BELEBELE: Benchmark.LLM_EVALUATION_HARNESS,
    # BigCodeBenchmark
    Task.BIG_CODE_BENCHMARK_COMPLETE: Benchmark.BIG_CODE_BENCHMARK,
    Task.BIG_CODE_BENCHMARK_INSTRUCT: Benchmark.BIG_CODE_BENCHMARK,
    # BigCodeEvaluationHarness
    Task.MULTIPLE_CLJCPP: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_CS: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_D: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_DART: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_ELIXIR: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_GO: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_HS: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_JAVA: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_JL: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_JS: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_LUA: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_MLPL: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_PHP: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_PY: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_R: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_RB: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_RKT: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_RS: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_SCALA: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_SH: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_SWIFT: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.MULTIPLE_TS: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.APPS_INTRODUCTORY: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.APPS_INTERVIEW: Benchmark.BIG_CODE_EVALUATION_HARNESS,
    Task.APPS_COMPETITION: Benchmark.BIG_CODE_EVALUATION_HARNESS,
}
